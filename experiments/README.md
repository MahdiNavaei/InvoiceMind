Experiments: running benchmarks and finetunes

Place experiment runs under `experiments/` with a JSON `manifest.json` describing:
- model, dataset, seed, command, result_path

Use the `Docs/Evaluation.md` benchmark plan as baseline. Keep experiments reproducible by checking in small config files (not large models or datasets).
